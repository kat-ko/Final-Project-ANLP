<q>For a language like English, this problem is generally regarded as trivial since words are delimited in English text by whitespace or marks of punctuation.<q>An initial step of any textÂ­ analysis task is the tokenization of the input into words.
