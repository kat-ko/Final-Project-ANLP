[CLS] [SEP] The problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (Grosz et al., 1995; Grosz and Sidner, 1998)), syntactic algorithms (e.g., (Hobbs, 1978; Lappin and Le- ass, 1994)), and supervised machine learning systems (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Ng and Cardie, 2002; Soon et al., 2001). [CLS] [SEP] Most computational models for coreference resolution rely on properties of the anaphor and candidate antecedent, such as lexical matching, grammatical and syntactic features, semantic agreement, and positional information. [CLS] [SEP] The focus of our work is on the use of contextual role knowledge for coreference resolution. [CLS] [SEP] A contextual role represents the role that a noun phrase plays in an event or relationship. [CLS] [SEP] Our work is motivated by the observation that contextual roles can be critically important in determining the referent of a noun phrase. [CLS] [SEP] Consider the following sentences: (a) Jose Maria Martinez, Roberto Lisandy, and Dino Rossy, who were staying at a Tecun Uman hotel, were kidnapped by armed men who took them to an unknown place. [CLS] [SEP] (b) After they were released... [CLS] [SEP] (c) After they blindfolded the men... [CLS] [SEP] In (b) “they” refers to the kidnapping victims, but in (c) “they” refers to the armed men. [CLS] [SEP] The role that each noun phrase plays in the kidnapping event is key to distinguishing these cases. [CLS] [SEP] The correct resolution in sentence (b) comes from knowledge that people who are kidnapped are often subsequently released. [CLS] [SEP] The correct resolution in sentence (c) depends on knowledge that kidnappers frequently blindfold their victims. [CLS] [SEP] We have developed a coreference resolver called BABAR that uses contextual role knowledge to make coreference decisions. [CLS] [SEP] BABAR employs information extraction techniques to represent and learn role relationships. [CLS] [SEP] Each pattern represents the role that a noun phrase plays in the surrounding context. [CLS] [SEP] BABAR uses unsupervised learning to acquire this knowledge from plain text without the need for annotated training data. [CLS] [SEP] Training examples are generated automatically by identifying noun phrases that can be easily resolved with their antecedents using lexical and syntactic heuristics. [CLS] [SEP] BABAR then computes statistics over the training examples measuring the frequency with which extraction patterns and noun phrases co-occur in coreference resolutions. [CLS] [SEP] In this paper, Section 2 begins by explaining how contextual role knowledge is represented and learned. [CLS] [SEP] Section 3 describes the complete coreference resolution model, which uses the contextual role knowledge as well as more traditional coreference features. [CLS] [SEP] Our coreference resolver also incorporates an existential noun phrase recognizer and a DempsterShafer probabilistic model to make resolution decisions. [CLS] [SEP] Section 4 presents experimen tal results on two corpora: the MUC4 terrorism corpus, and Reuters texts about natural disasters. [CLS] [SEP] Our results show that BABAR achieves good performance in both domains, and that the contextual role knowledge improves performance, especially on pronouns. [CLS] [SEP] Finally, Section 5 explains how BABAR relates to previous work, and Section 6 summarizes our conclusions. [CLS] [SEP] In this section, we describe how contextual role knowledge is represented and learned. [CLS] [SEP] Section 2.1 describes how BABAR generates training examples to use in the learning process. [CLS] [SEP] We refer to this process as Reliable Case Resolution because it involves finding cases of anaphora that can be easily resolved with their antecedents. [CLS] [SEP] Section 2.2 then describes our representation for contextual roles and four types of contextual role knowledge that are learned from the training examples. [CLS] [SEP] 2.1 Reliable Case Resolutions. [CLS] [SEP] The first step in the learning process is to generate training examples consisting of anaphor/antecedent resolutions. [CLS] [SEP] BABAR uses two methods to identify anaphors that can be easily and reliably resolved with their antecedent: lexical seeding and syntactic seeding. [CLS] [SEP] 2.1.1 Lexical Seeding It is generally not safe to assume that multiple occurrences of a noun phrase refer to the same entity. [CLS] [SEP] For example, the company may refer to Company X in one paragraph and Company Y in another. [CLS] [SEP] However, lexically similar NPs usually refer to the same entity in two cases: proper names and existential noun phrases. [CLS] [SEP] BABAR uses a named entity recognizer to identify proper names that refer to people and companies. [CLS] [SEP] Proper names are assumed to be coreferent if they match exactly, or if they closely match based on a few heuristics. [CLS] [SEP] For example, a person’s full name will match with just their last name (e.g., “George Bush” and “Bush”), and a company name will match with and without a corporate suffix (e.g., “IBM Corp.” and “IBM”). [CLS] [SEP] Proper names that match are resolved with each other. [CLS] [SEP] The second case involves existential noun phrases (Allen, 1995), which are noun phrases that uniquely specify an object or concept and therefore do not need a prior referent in the discourse. [CLS] [SEP] In previous work (Bean and Riloff, 1999), we developed an unsupervised learning algorithm that automatically recognizes definite NPs that are existential without syntactic modification because their meaning is universally understood. [CLS] [SEP] For example, a story can mention “the FBI”, “the White House”, or “the weather” without any prior referent in the story. [CLS] [SEP] Although these existential NPs do not need a prior referent, they may occur multiple times in a document. [CLS] [SEP] By definition, each existential NP uniquely specifies an object or concept, so we can infer that all instances of the same existential NP are coreferent (e.g., “the FBI” always refers to the same entity). [CLS] [SEP] Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved. [CLS] [SEP] Table 1 briefly describes the seven syntactic heuristics used by BABAR to resolve noun phrases. [CLS] [SEP] Words and punctuation that appear in brackets are considered optional. [CLS] [SEP] The anaphor and antecedent appear in boldface. [CLS] [SEP] 1. [CLS] [SEP] Reflexive pronouns with only 1 NP in scope.. [CLS] [SEP] Ex: The regime gives itself the right... [CLS] [SEP] 2. [CLS] [SEP] Relative pronouns with only 1 NP in scope.. [CLS] [SEP] Ex: The brigade, which attacked ...