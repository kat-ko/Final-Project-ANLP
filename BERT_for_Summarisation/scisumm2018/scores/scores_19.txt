('BERT Result: <q>Lexicographers cannot possibly keep pace with language evolution: sense distinctions are continually made and merged, words are coined or become obsolete, and technical terms migrate into the vernacular.<q>Unfortunately, these resource are extremely time- consuming and labour-intensive to manually develop and maintain, requiring considerable linguistic and domain expertise.\n\n Gold Summary: Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET. Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses. Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNETâ€™s hierarchical structure to create many annotated training instances from the synset glosses. Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems. Similarity Vector-space models of similarity are based on the distributional hypothesis that similar words appear in similar contexts. Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns. Each synonym votes for each of its supersenses from WORDNET 1.6 using the similarity score from our synonym extractor. Such a corpus is needed to acquire reliable contextual information for the often very rare nouns we are attempting to supersense tag.\n Scores', [{'rouge-1': {'f': 0.1106719336355826, 'p': 0.2857142857142857, 'r': 0.06862745098039216}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.08556149378478095, 'p': 0.18604651162790697, 'r': 0.05555555555555555}}])