("BERT Result: <q>Furthermore, CFG's are readily fit with a probability distribution (to make probabilistic CFG's--or PCFG's), rendering them suitable for ambiguous languages through the maximum a posteriori rule of choosing the most probable parse.<q>For each nonterminal symbol, a (normalized) probability is placed on the set of all productions from that symbol.\n\n Gold Summary: Estimation of Probabilistic Context-Free Grammars The assignment of probabilities to the productions of a context-free grammar may generate an improper distribution: the probability of all finite parse trees is less than one. We show here that estimated production probabilities always yield proper distributions. If the corpus is unparsed then there is an iterative approach to maximum-likelihood estimation (the EM or Baum-Welsh algorithm--again, see Section 2) and the same question arises: do we get actual probabilities or do the estimated PCFG&apos;s assign some mass to infinite trees? We will show that in both cases the estimated probability is tight. (8~fl)ea ~(B --~/3) = ~=lf(B --~/3;cai) (3) c~ s.t. H &lt;B-~)e~ ~i=lf(B ---+o4cai) The maximum-likelihood estimator is the natural, &quot;relative frequency,&quot; estimator. Letting ~y denote {w Efk Y(w) = Y}, the likelihood of the corpus becomes n H E H P(A--&apos;~oL)f(A~;~)&quot; i=1 ~OE~y(~i) (A---~o~)ER And the maximum-likelihood equation becomes + p(B fl) Ei=l EwEfly(wi,I-I(A--.)cR p(A -~ a)f(A-~&quot;;~) = 0 fT(B ~ /3) = ~iL1 Ep~f(B ~ fl;w)lw E ~y(~,)] (4) ,~s,,, ~Ei=IEpV(&quot; a;w)lw E ~Y(o~,)] E(B_~,E B ~ where E~ is expectation under fi and where &quot;]w E~-~y(wi)&quot; means &quot;conditioned on 0.2E ~-~Y(wi)&apos;&quot; There is no hope for a closed form solution, but (4) does suggest an iteration scheme, which, as it turns out, &quot;climbs&quot; the likelihood surface (though there are no guarantees about approaching a global maximum): Let P0 be an arbitrary assignment respecting (1). Dempster, Laird, and Rubin [1977] put the idea into a much more general setting and coined the Chi and Geman Probabilistic Context-Free Grammars term EM for Expectation-Maximization.\n Scores", [{'rouge-1': {'f': 0.11428571157188214, 'p': 0.35294117647058826, 'r': 0.06818181818181818}, 'rouge-2': {'f': 0.012779550031132859, 'p': 0.04, 'r': 0.0076045627376425855}, 'rouge-l': {'f': 0.07563024903431974, 'p': 0.2, 'r': 0.046632124352331605}}])