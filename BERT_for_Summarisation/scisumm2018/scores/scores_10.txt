('BERT Result: <q>As can be seen at the bottom of Figure 1, we plan to add a component to ourcurrent system that allows users to ask questions asthey read a story.<q>They may then choose to receiveeither a precise answer or a question-focused summary.\n\n Gold Summary: Using Random Walks for Question-focused Sentence Retrieval Our goal is to build a question-focused sentence retrieval mechanism using a topic-sensitive version ofthe LexRank method. The output of our system, a ranked list of sentences relevant to the userâ€™s question, can be subsequently used as input to an answer selection system in order to find specific answers from the extracted sentences. Alternatively, the sentences canbe returned to the user as a question-focused summary. To apply LexRank, a similarity graph is producedfor the sentences in an input document set. In thegraph, each node represents a sentence. There areedges between nodes for which the cosine similarity between the respective pair of sentences exceedsa given threshold. The degree of a given node isan indication of how much information the respective sentence has in common with other sentences. In topic-sensitive LexRank, we first stem all of thesentences in a set of articles and compute word IDFsby the following formula: In a Web-based news summarization setting, users of our system could choose to see the retrieved sentences (asin Table 9) as a question-focused summary.\n Scores', [{'rouge-1': {'f': 0.17194569822321415, 'p': 0.4418604651162791, 'r': 0.10674157303370786}, 'rouge-2': {'f': 0.0365296772652783, 'p': 0.09523809523809523, 'r': 0.022598870056497175}, 'rouge-l': {'f': 0.1447368384219184, 'p': 0.2972972972972973, 'r': 0.09565217391304348}}])